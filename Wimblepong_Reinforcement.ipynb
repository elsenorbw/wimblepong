{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrbenbot/wimblepong/blob/main/Wimblepong_Reinforcement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NkhwGXZyRfWZ",
        "outputId": "d0951b06-d67c-44a5-870f-b915a972a932"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "# Step 1: Setup Google Colab Environment\n",
        "%pip install gym\n",
        "%pip install stable-baselines3[extra]\n",
        "%pip install imageio pillow\n",
        "%pip install tensorflowjs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYCJyx3kJikU",
        "outputId": "82a8d059-101c-4f13-a330-9b60497f26bf"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRePUZ1QRh6C",
        "outputId": "77d7a869-ecdb-433d-9697-c1a2a56dae70"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "from gymnasium import spaces\n",
        "import gymnasium as gym\n",
        "\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "import os\n",
        "import imageio\n",
        "import glob\n",
        "import math\n",
        "\n",
        "from IPython.display import display, Image, HTML\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import torch as th\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Check versions\n",
        "print(\"gym version:\", gym.__version__)\n",
        "print(\"stable-baselines3 version:\", stable_baselines3.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLzB2yLbociM"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "COURT_HEIGHT = 800\n",
        "COURT_WIDTH = 1200\n",
        "PADDLE_HEIGHT = 90\n",
        "PADDLE_WIDTH = 15\n",
        "BALL_RADIUS = 12\n",
        "INITIAL_BALL_SPEED = 10\n",
        "PADDLE_SPEED_DIVISOR = 15  # Example value, adjust as needed\n",
        "PADDLE_CONTACT_SPEED_BOOST_DIVISOR = 4  # Example value, adjust as needed\n",
        "SPEED_INCREMENT = 0.6  # Example value, adjust as needed\n",
        "SERVING_HEIGHT_MULTIPLIER = 2  # Example value, adjust as needed\n",
        "PLAYER_COLOURS = {'Player1': 'blue', 'Player2': 'red'}\n",
        "MAX_COMPUTER_PADDLE_SPEED = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZzIav-qUBzp"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "rewards_map = {\n",
        "    \"hit_paddle\": lambda _: 50,\n",
        "    \"score_point\": lambda _: 100,\n",
        "    \"conceed_point\": lambda ball, paddle, rally_length: -abs(ball['y'] - paddle['y']) / max(rally_length, 1),\n",
        "    \"serve\": lambda ball_speed: ball_speed / 10,\n",
        "    \"paddle_movement\": lambda dy: abs(dy) / 15,\n",
        "    \"ball_distance\": lambda ball, paddle: -abs(ball['y'] - (paddle['y'] + PADDLE_HEIGHT))\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExmAn7VtUakq"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "class Player:\n",
        "    Player1 = 'Player1'\n",
        "    Player2 = 'Player2'\n",
        "\n",
        "class PlayerPositions:\n",
        "    Initial = 'Initial'\n",
        "    Reversed = 'Reversed'\n",
        "\n",
        "class GameEventType:\n",
        "    ResetBall = 'ResetBall'\n",
        "    Serve = 'Serve'\n",
        "    WallContact = 'WallContact'\n",
        "    HitPaddle = 'HitPaddle'\n",
        "    ScorePointLeft = 'ScorePointLeft'\n",
        "    ScorePointRight = 'ScorePointRight'\n",
        "\n",
        "def get_bounce_angle(paddle_y, paddle_height, ball_y):\n",
        "    relative_intersect_y = (paddle_y + (paddle_height / 2)) - ball_y\n",
        "    normalized_relative_intersect_y = relative_intersect_y / (paddle_height / 2)\n",
        "    return normalized_relative_intersect_y * (math.pi / 4)\n",
        "\n",
        "class CustomPongEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(CustomPongEnv, self).__init__()\n",
        "        self.action_space = spaces.Box(low=np.array([0, -60]), high=np.array([1, 60]), dtype=np.float32)\n",
        "        # i have updated this. Please provide me with just the observation space declaration please\n",
        "\n",
        "            # float(state['ball']['x']),\n",
        "            # float(state['ball']['y']),\n",
        "            # float(state['ball']['dx']),\n",
        "            # float(state['ball']['dy']),\n",
        "            # float(paddle['x']),\n",
        "            # float(paddle['y']),\n",
        "            # float(int(state['ball']['serve_mode'])),\n",
        "            # float(is_server),\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0, 0, -np.inf, -np.inf, 0, 0, 0, 0], dtype=np.float32),\n",
        "            high=np.array([COURT_WIDTH, COURT_HEIGHT, np.inf, np.inf, COURT_WIDTH, COURT_HEIGHT, 1, 1], dtype=np.float32)\n",
        "        )\n",
        "        # Define the possible starting states\n",
        "        self.starting_states = [\n",
        "           {'server': Player.Player2, 'positions_reversed': False, 'opponent': Player.Player1, 'player': Player.Player2},\n",
        "           {'server': Player.Player2, 'positions_reversed': True, 'opponent': Player.Player1, 'player': Player.Player2},\n",
        "           {'server': Player.Player1, 'positions_reversed': False, 'opponent': Player.Player1, 'player': Player.Player2},\n",
        "           {'server': Player.Player1, 'positions_reversed': True, 'opponent': Player.Player1, 'player': Player.Player2},\n",
        "        ]\n",
        "\n",
        "        self.serve_delay = 50\n",
        "        self.serve_delay_counter = 0\n",
        "        self.direction = 15\n",
        "        self.is_done = False\n",
        "        self.frame_count = 0\n",
        "\n",
        "        self.last_event = None\n",
        "\n",
        "        # Initialize the game state\n",
        "        self.reset(seed=0)\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = gym.utils.seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def reset(self, seed=None):\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            self.seed(seed)\n",
        "        # Select a random starting state\n",
        "        starting_state = np.random.choice(self.starting_states)\n",
        "\n",
        "        # Set the server, positions, and computer player based on the starting state\n",
        "        server = starting_state['server']\n",
        "        positions_reversed = starting_state['positions_reversed']\n",
        "        computer = starting_state['opponent']\n",
        "        player = starting_state['player']\n",
        "\n",
        "        # Initialize the game state\n",
        "        self.state = {\n",
        "            'server': server,\n",
        "            'positions_reversed': positions_reversed,\n",
        "            'opponent': computer,\n",
        "            'player': player,\n",
        "            Player.Player1: {'x': 0, 'y': COURT_HEIGHT // 2 - PADDLE_HEIGHT // 2, 'dy': 0, 'width': PADDLE_WIDTH, 'height': PADDLE_HEIGHT, 'colour': 'blue'},\n",
        "            Player.Player2: {'x': COURT_WIDTH - PADDLE_WIDTH, 'y': COURT_HEIGHT // 2 - PADDLE_HEIGHT // 2, 'dy': 0, 'width': PADDLE_WIDTH, 'height': PADDLE_HEIGHT, 'colour': 'red'},\n",
        "            'ball': {'x': COURT_WIDTH // 2, 'y': COURT_HEIGHT // 2, 'dx': INITIAL_BALL_SPEED, 'dy': INITIAL_BALL_SPEED, 'radius': BALL_RADIUS, 'speed': INITIAL_BALL_SPEED, 'serve_mode': True, 'score_mode': False, 'score_mode_timeout': 0},\n",
        "            'stats': {'rally_length': 0, 'serve_speed': INITIAL_BALL_SPEED, 'server': server}\n",
        "        }\n",
        "        self.is_done = False\n",
        "\n",
        "        # Apply the meta game state adjustments\n",
        "        self.apply_meta_game_state()\n",
        "        self.serve_delay_counter = 0\n",
        "        self.direction = 30 * np.random.rand()\n",
        "        self.serve_delay = 100 * np.random.rand()\n",
        "        self.direction = self.direction if np.random.rand() > 0.5 else -self.direction\n",
        "\n",
        "        # Initialize frame count and ensure frames directory exists\n",
        "        # self.frame_count = 0\n",
        "        if not os.path.exists('frames'):\n",
        "            os.makedirs('frames')\n",
        "        return self._get_obs(), {}\n",
        "\n",
        "    def apply_meta_game_state(self):\n",
        "        game_state = self.state\n",
        "        serving_player = game_state['server']\n",
        "        positions_reversed = game_state['positions_reversed']\n",
        "\n",
        "        # Set paddle heights\n",
        "        if serving_player == Player.Player1:\n",
        "            self.state[Player.Player1] = PADDLE_HEIGHT * SERVING_HEIGHT_MULTIPLIER\n",
        "            self.state[Player.Player2] = PADDLE_HEIGHT\n",
        "        else:\n",
        "            self.state[Player.Player1] = PADDLE_HEIGHT\n",
        "            self.state[Player.Player2] = PADDLE_HEIGHT * SERVING_HEIGHT_MULTIPLIER\n",
        "\n",
        "        # Set paddle positions\n",
        "        if positions_reversed:\n",
        "            self.state[Player.Player1]['x'] = COURT_WIDTH - PADDLE_WIDTH\n",
        "            self.state[Player.Player2]['x'] = 0\n",
        "        else:\n",
        "            self.state[Player.Player1]['x'] = 0\n",
        "            self.state[Player.Player2]['x'] = COURT_WIDTH - PADDLE_WIDTH\n",
        "\n",
        "        ball = self.state['ball']\n",
        "        server_is_left = (serving_player == Player.Player1 and not positions_reversed) or (serving_player == Player.Player2 and positions_reversed)\n",
        "        # Set ball start position based on meta state\n",
        "        ball['y'] = self.state[serving_player]['height'] / 2 + self.state[serving_player]['y']\n",
        "        ball['x'] = self.state[serving_player]['width'] + ball['radius'] if server_is_left else COURT_WIDTH - self.state[serving_player]['width'] - ball['radius']\n",
        "        ball['speed'] = INITIAL_BALL_SPEED\n",
        "        ball['serve_mode'] = True\n",
        "        ball['score_mode'] = False\n",
        "        ball['score_mode_timeout'] = 0\n",
        "        self.state['stats']['rally_length'] = 0\n",
        "\n",
        "    def step(self, action):\n",
        "        # Encode actions\n",
        "        button_pressed = action[0] > 0.5  # First dimension is button_pressed\n",
        "        paddle_direction = action[1]     # Second dimension is paddle_direction\n",
        "        model_player_actions = {'button_pressed': button_pressed, 'paddle_direction': paddle_direction}\n",
        "        computer_player_actions = self.get_computer_player_actions(self.state['opponent'])\n",
        "        actions = {self.state['opponent']:computer_player_actions,self.state['player']:model_player_actions }\n",
        "        \n",
        "        # Update state and collect reward\n",
        "        reward = self.update_game_state(self.state, actions, 0.8)\n",
        "        obs = self._get_obs()\n",
        "        info = {}\n",
        "        terminated = self.check_done()\n",
        "        truncated = False  # Add logic if you want to support truncation\n",
        "\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def update_game_state(self, actions, delta_time):\n",
        "        reward = 0\n",
        "        game_state = self.state\n",
        "        ball = game_state['ball']\n",
        "        stats = game_state['stats']\n",
        "        server = game_state['server']\n",
        "        paddle_left, paddle_right = (game_state[Player.Player2],game_state[Player.Player1]) if game_state['positions_reversed'] else (game_state[Player.Player1],game_state[Player.Player2])\n",
        "        model_is_left = (game_state['player'] == Player.Player1 and not game_state['positions_reversed']) or (game_state['player'] == Player.Player2 and game_state['positions_reversed'])\n",
        "        if ball['score_mode']:\n",
        "            if ball['score_mode_timeout'] < 50:\n",
        "                ball['score_mode_timeout'] += delta_time\n",
        "        elif ball['serve_mode']:\n",
        "            serving_from_left = (server == Player.Player1 and not game_state['positions_reversed']) or (server == Player.Player2 and game_state['positions_reversed'])\n",
        "            if serving_from_left:\n",
        "                ball['x'] = game_state[server]['width'] + ball['radius']\n",
        "            else:\n",
        "                ball['x'] = COURT_WIDTH - game_state[server]['width'] - ball['radius']\n",
        "            if actions[server]['button_pressed']:\n",
        "                ball['speed'] = INITIAL_BALL_SPEED\n",
        "                ball['dx'] = -INITIAL_BALL_SPEED\n",
        "                ball['serve_mode'] = False\n",
        "                stats['rally_length'] += 1\n",
        "                stats['serveSpeed'] = abs(ball['dy']) + abs(ball['dx'])\n",
        "                stats['server'] = server\n",
        "\n",
        "                if game_state['player'] == server:\n",
        "                  reward += rewards_map['serve'](abs(ball['dy']) + abs(ball['dx']))\n",
        "            ball['dy'] = (game_state[server]['y'] + game_state[server]['height'] / 2 - ball['y']) / PADDLE_SPEED_DIVISOR\n",
        "            ball['y'] += ball['dy'] * delta_time\n",
        "        else:\n",
        "            ball['x'] += ball['dx'] * delta_time\n",
        "            ball['y'] += ball['dy'] * delta_time\n",
        "\n",
        "            # Check for collisions with top and bottom walls\n",
        "            if ball['y'] - ball['radius'] < 0:\n",
        "                ball['dy'] = -ball['dy']\n",
        "                ball['y'] = ball['radius']  # Adjust ball position to avoid sticking\n",
        "            elif ball['y'] + ball['radius'] > COURT_HEIGHT:\n",
        "                ball['dy'] = -ball['dy']\n",
        "                ball['y'] = COURT_HEIGHT - ball['radius']  # Adjust ball position to avoid sticking\n",
        "\n",
        "            # Update ball collision detection and response\n",
        "            if ball['x'] - ball['radius'] < paddle_left['x'] + paddle_left['width'] and ball['y'] + ball['radius'] > paddle_left['y'] and ball['y'] - ball['radius'] < paddle_left['y'] + paddle_left['height']:\n",
        "                bounce_angle = get_bounce_angle(paddle_left['y'], paddle_left['height'], ball['y'])\n",
        "                ball['dx'] = (ball['speed'] + abs(paddle_left['dy']) / PADDLE_CONTACT_SPEED_BOOST_DIVISOR) * math.cos(bounce_angle)\n",
        "                ball['dy'] = (ball['speed'] + abs(paddle_left['dy']) / PADDLE_CONTACT_SPEED_BOOST_DIVISOR) * -math.sin(bounce_angle)\n",
        "                ball['x'] = paddle_left['x'] + paddle_left['width'] + ball['radius']  # Adjust ball position to avoid sticking\n",
        "                ball['speed'] += SPEED_INCREMENT\n",
        "                stats['rally_length'] += 1\n",
        "                if paddle_left == game_state['player']:\n",
        "                  reward += rewards_map[\"hit_paddle\"](stats['rally_length'])\n",
        "            elif ball['x'] + ball['radius'] > paddle_right['x'] and ball['y'] + ball['radius'] > paddle_right['y'] and ball['y'] - ball['radius'] < paddle_right['y'] + paddle_right['height']:\n",
        "                bounce_angle = get_bounce_angle(paddle_right['y'], paddle_right['height'], ball['y'])\n",
        "                ball['dx'] = -(ball['speed'] + abs(paddle_right['dy']) / PADDLE_CONTACT_SPEED_BOOST_DIVISOR) * math.cos(bounce_angle)\n",
        "                ball['dy'] = (ball['speed'] + abs(paddle_right['dy']) / PADDLE_CONTACT_SPEED_BOOST_DIVISOR) * -math.sin(bounce_angle)\n",
        "                ball['x'] = paddle_right['x'] - ball['radius']  # Adjust ball position to avoid sticking\n",
        "                ball['speed'] += SPEED_INCREMENT\n",
        "                stats['rally_length'] += 1\n",
        "                if paddle_right == game_state['player']:\n",
        "                  reward += rewards_map[\"hit_paddle\"](stats['rally_length'])\n",
        "            # Check for scoring\n",
        "            if ball['x'] - ball['radius'] < 0:\n",
        "                ball['scoreMode'] = True\n",
        "                self.is_done = True\n",
        "                if model_is_left:\n",
        "                  reward += rewards_map['conceed_point'](ball, paddle_left, stats['rally_length'])\n",
        "                else:\n",
        "                  reward += rewards_map['score_point'](stats['rally_length'])\n",
        "            elif ball['x'] + ball['radius'] > COURT_WIDTH:\n",
        "                self.is_done = True\n",
        "                ball['scoreMode'] = True\n",
        "                if not model_is_left:\n",
        "                  reward += rewards_map['conceed_point'](ball, paddle_right, stats['rally_length'])\n",
        "                else:\n",
        "                  reward += rewards_map['score_point'](stats['rally_length'])\n",
        "\n",
        "        if game_state['positions_reversed']:\n",
        "            game_state[Player.Player1]['dy'] = actions[Player.Player1]['paddle_direction']\n",
        "            game_state[Player.Player2]['dy'] = -actions[Player.Player2]['paddle_direction']\n",
        "        else:\n",
        "            game_state[Player.Player1]['dy'] = -actions[Player.Player1]['paddle_direction']\n",
        "            game_state[Player.Player2]['dy'] = actions[Player.Player2]['paddle_direction']\n",
        "\n",
        "\n",
        "        \n",
        "        game_state[Player.Player1]['y'] += game_state[Player.Player1]['dy'] * delta_time\n",
        "        game_state[Player.Player2]['y'] += game_state[Player.Player2]['dy'] * delta_time\n",
        "\n",
        "        if model_is_left:\n",
        "          reward += rewards_map['paddle_movement'](abs(paddle_left['dy']))\n",
        "          reward += rewards_map['ball_distance'](ball, paddle_left)\n",
        "        else:\n",
        "          reward += rewards_map['ball_distance'](ball, paddle_right)\n",
        "          reward += rewards_map['paddle_movement'](abs(paddle_right['dy']))\n",
        "\n",
        "\n",
        "        # Ensure paddles stay within screen bounds\n",
        "        if paddle_left['y'] < 0:\n",
        "            paddle_left['y'] = 0\n",
        "        if paddle_left['y'] + paddle_left['height'] > COURT_HEIGHT:\n",
        "            paddle_left['y'] = COURT_HEIGHT - paddle_left['height']\n",
        "\n",
        "        if paddle_right['y'] < 0:\n",
        "            paddle_right['y'] = 0\n",
        "        if paddle_right['y'] + paddle_right['height'] > COURT_HEIGHT:\n",
        "            paddle_right['y'] = COURT_HEIGHT - paddle_right['height']\n",
        "\n",
        "\n",
        "        reward += 0.01 * stats['rally_length']\n",
        "        return reward\n",
        "\n",
        "    def get_computer_player_actions(self, player):\n",
        "        state = self.state\n",
        "        is_left = (player == Player.Player1 and not state['positions_reversed']) or (player == Player.Player2 and state['positions_reversed'])\n",
        "        if state['ball']['scoreMode']:\n",
        "            return {'button_pressed': False, 'paddle_direction': 0}\n",
        "\n",
        "        paddle = state[player]\n",
        "        if state['ball']['serve_mode']:\n",
        "            if paddle['y'] <= 0 or paddle['y'] + paddle['height'] >= COURT_HEIGHT:\n",
        "                self.direction = -self.direction\n",
        "            if self.serve_delay_counter > self.serve_delay:\n",
        "                return {'button_pressed': True, 'paddle_direction': self.direction}\n",
        "            else:\n",
        "                self.serve_delay_counter += 1\n",
        "                return {'button_pressed': False, 'paddle_direction': self.direction}\n",
        "\n",
        "\n",
        "        if is_left:\n",
        "          return {\n",
        "              'button_pressed': False,\n",
        "              'paddle_direction': self.bounded_value(\n",
        "                  paddle['y'] - state['ball']['y'] + paddle['height'] / 2 + (np.random.rand() - 0.5) * 2,\n",
        "                  -MAX_COMPUTER_PADDLE_SPEED,\n",
        "                  MAX_COMPUTER_PADDLE_SPEED\n",
        "              )\n",
        "          }\n",
        "        else:\n",
        "          return {\n",
        "              'button_pressed': False,\n",
        "              'paddle_direction': -self.bounded_value(\n",
        "                  paddle['y'] - state['ball']['y'] + paddle['height'] / 2 + (np.random.rand() - 0.5) * 2,\n",
        "                  -MAX_COMPUTER_PADDLE_SPEED,\n",
        "                  MAX_COMPUTER_PADDLE_SPEED\n",
        "              )\n",
        "          }\n",
        "\n",
        "    def bounded_value(self, value, min_value, max_value):\n",
        "        return max(min_value, min(max_value, value))\n",
        "\n",
        "    def _get_obs(self):\n",
        "        state = self.state\n",
        "        player = state['player']\n",
        "        is_server = 1 if self.state['server'] == player else 0\n",
        "        paddle = state[player]\n",
        "        return np.array([\n",
        "            float(state['ball']['x']),\n",
        "            float(state['ball']['y']),\n",
        "            float(state['ball']['dx']),\n",
        "            float(state['ball']['dy']),\n",
        "            float(paddle['x']),\n",
        "            float(paddle['y']),\n",
        "            float(int(state['ball']['serve_mode'])),\n",
        "            float(is_server),\n",
        "        ], dtype=np.float32)\n",
        "\n",
        "\n",
        "    def check_done(self):\n",
        "        # Determine if the episode is done\n",
        "        if self.state['stats']['rally_length'] > 100:\n",
        "          return True\n",
        "        return self.is_done\n",
        "\n",
        "    def render(self, mode='human', close=False):\n",
        "        if close:\n",
        "            plt.close()\n",
        "            return\n",
        "\n",
        "        if not hasattr(self, 'fig'):\n",
        "            self.fig, self.ax = plt.subplots()\n",
        "            self.ax.set_xlim(0, COURT_WIDTH)\n",
        "            self.ax.set_ylim(0, COURT_HEIGHT)\n",
        "            self.ax.set_aspect('equal')\n",
        "            plt.gca().invert_yaxis()  # Invert y-axis to match the coordinate system\n",
        "\n",
        "        self.ax.clear()\n",
        "        self.ax.set_xlim(0, COURT_WIDTH)\n",
        "        self.ax.set_ylim(0, COURT_HEIGHT)\n",
        "\n",
        "        # Draw paddles\n",
        "        paddle1 = self.state[Player.Player1]\n",
        "        paddle2 = self.state[Player.Player2]\n",
        "\n",
        "\n",
        "        self.ax.add_patch(patches.Rectangle((paddle1['x'], paddle1['y']), paddle1['width'], paddle1['height'], color=paddle1['colour']))\n",
        "        self.ax.add_patch(patches.Rectangle((paddle2['x'], paddle2['y']), paddle2['width'], paddle2['height'], color=paddle2['colour']))\n",
        "\n",
        "        # Draw ball\n",
        "        ball = self.state['ball']\n",
        "        self.ax.add_patch(patches.Circle((ball['x'], ball['y']), ball['radius'], color='black'))\n",
        "\n",
        "        # Capture the frame\n",
        "        plt.draw()\n",
        "        frame_path = f'frames/frame_{self.frame_count:04d}.png'\n",
        "        self.fig.savefig(frame_path)\n",
        "        self.frame_count += 1\n",
        "\n",
        "    def close(self):\n",
        "        if hasattr(self, 'fig'):\n",
        "            plt.close(self.fig)\n",
        "\n",
        "        # Check if frames directory exists\n",
        "        if not os.path.exists('frames'):\n",
        "            print(\"No frames directory found, skipping video creation.\")\n",
        "            return\n",
        "\n",
        "        # Create GIF from frames\n",
        "        with imageio.get_writer('pong_game.gif', mode='I', duration=0.005) as writer:\n",
        "            for filename in sorted(glob.glob('frames/frame_*.png')):\n",
        "                image = imageio.imread(filename)\n",
        "                writer.append_data(image)\n",
        "\n",
        "        # Display the GIF\n",
        "        display(Image(filename='pong_game.gif'))\n",
        "\n",
        "        # Remove frames\n",
        "        for file in os.listdir('frames'):\n",
        "            os.remove(os.path.join('frames', file))\n",
        "        os.rmdir('frames')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "w4LjxARS9zCF",
        "outputId": "b3909ed0-3440-41e8-a8b4-cc1463e9388a"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "# Test the custom environment\n",
        "env = CustomPongEnv()\n",
        "obs = env.reset()\n",
        "print(\"Initial observation:\", obs)\n",
        "\n",
        "for i in range(100):\n",
        "    action = env.action_space.sample()  # Sample random action\n",
        "    obs, reward, done, info, _ = env.step(action)\n",
        "    print(\"Action taken:\", action)\n",
        "    print(\"Observation:\", obs)\n",
        "    print(\"Reward:\", reward)\n",
        "    print('iteration:', i)\n",
        "    print(\"Done:\", done)\n",
        "    env.render()\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-9NVtRTZyhns",
        "outputId": "62e3fb29-9a6f-4689-cb4e-1e241b1dbddc"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "# Initialize the custom environment with the updated reward function\n",
        "env = CustomPongEnv()\n",
        "\n",
        "# Check the environment (optional, to ensure the environment follows Gym's API)\n",
        "check_env(env, warn=True)\n",
        "iteration = 0\n",
        "name = \"e\"\n",
        "path = \"/content/drive/MyDrive/wimblepong\"\n",
        "# Load the previously trained model or initialize a new one\n",
        "try:\n",
        "    model = PPO.load(f\"{path}/ppo_custom_pong_{name}.{iteration}\", env=env)\n",
        "    # model = PPO.load(f\"./logs/best_model\", env=env)\n",
        "except:\n",
        "    print('creating new model')\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1, learning_rate=3e-4, n_steps=2048, batch_size=64, gamma=0.99, ent_coef=0.01)\n",
        "\n",
        "# Define evaluation callback\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./logs/',\n",
        "                             log_path='./logs/', eval_freq=1000,\n",
        "                             deterministic=False, render=False)\n",
        "\n",
        "# Continue training the model with more iterations\n",
        "model.learn(total_timesteps=100000, callback=eval_callback)\n",
        "\n",
        "# Save the retrained model\n",
        "model.save(f\"{path}/ppo_custom_pong_{name}.{iteration + 1}\")\n",
        "\n",
        "# Evaluate the retrained model\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gp2wbu_aiXgH",
        "outputId": "97870225-37b1-4855-eb66-e1e5b829847c"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "# Evaluate the trained model\n",
        "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)\n",
        "print(f\"Mean reward: {mean_reward} +/- {std_reward}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "FQZDHQX5lGpv",
        "outputId": "c866fd5a-6293-4aee-e3ed-1eabb6df0c18"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "env = CustomPongEnv()\n",
        "# model = PPO.load(f\"{path}/ppo_custom_pong_{name}.{iteration+1}\")\n",
        "model = PPO.load(f\"./logs/best_model\")\n",
        "\n",
        "obs, _ = env.reset()\n",
        "for _ in range(1000):\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, done, info, _ = env.step(action)\n",
        "    print(rewards)\n",
        "    env.render()\n",
        "    if done:\n",
        "        break\n",
        "        print(\"resetting due to done\")\n",
        "        print(env.state)\n",
        "        obs, _ = env.reset()\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgjmNUdl1WcA",
        "outputId": "1a8b5f65-c8d4-4747-ca3d-96417bb07959"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "# Load the trained PPO model\n",
        "model = PPO.load(f\"{path}/ppo_custom_pong_{iteration+1}\")\n",
        "\n",
        "# Extract the PyTorch model's weights\n",
        "policy_weights = model.policy.state_dict()\n",
        "\n",
        "# Define the TensorFlow model\n",
        "class TfPPOPolicy(tf.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(TfPPOPolicy, self).__init__()\n",
        "        self.fc1 = layers.Dense(64, activation='tanh', input_shape=(input_dim,))\n",
        "        self.fc2 = layers.Dense(64, activation='tanh')\n",
        "        self.action_head = layers.Dense(output_dim)\n",
        "        self.value_head = layers.Dense(1)\n",
        "\n",
        "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, 9], dtype=tf.float32)])\n",
        "    def __call__(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        action_logits = self.action_head(x)\n",
        "        value = self.value_head(x)\n",
        "        return action_logits, value\n",
        "\n",
        "    def predict(self, x):\n",
        "        action_logits, value = self.__call__(x)\n",
        "        # Apply sigmoid to the buttonPressed logits to constrain between 0 and 1\n",
        "        buttonPressed = tf.sigmoid(action_logits[:, 0])\n",
        "        paddleDirection = action_logits[:, 1]\n",
        "        return buttonPressed, paddleDirection\n",
        "\n",
        "\n",
        "# Create the TensorFlow model\n",
        "input_dim = 9  # Your observation space dimension\n",
        "output_dim = 2  # Number of actions\n",
        "tf_policy = TfPPOPolicy(input_dim, output_dim)\n",
        "\n",
        "# Load weights into the TensorFlow model\n",
        "tf_policy.fc1.build((None, input_dim))\n",
        "tf_policy.fc1.set_weights([\n",
        "    policy_weights['mlp_extractor.policy_net.0.weight'].cpu().numpy().T,\n",
        "    policy_weights['mlp_extractor.policy_net.0.bias'].cpu().numpy()\n",
        "])\n",
        "\n",
        "tf_policy.fc2.build((None, 64))\n",
        "tf_policy.fc2.set_weights([\n",
        "    policy_weights['mlp_extractor.policy_net.2.weight'].cpu().numpy().T,\n",
        "    policy_weights['mlp_extractor.policy_net.2.bias'].cpu().numpy()\n",
        "])\n",
        "\n",
        "tf_policy.action_head.build((None, 64))\n",
        "tf_policy.action_head.set_weights([\n",
        "    policy_weights['action_net.weight'].cpu().numpy().T,\n",
        "    policy_weights['action_net.bias'].cpu().numpy()\n",
        "])\n",
        "\n",
        "tf_policy.value_head.build((None, 64))\n",
        "tf_policy.value_head.set_weights([\n",
        "    policy_weights['value_net.weight'].cpu().numpy().T,\n",
        "    policy_weights['value_net.bias'].cpu().numpy()\n",
        "])\n",
        "\n",
        "# Save the wrapped policy as a TensorFlow SavedModel\n",
        "saved_model_path = \"./saved_model\"\n",
        "tf.saved_model.save(tf_policy, saved_model_path)\n",
        "\n",
        "# Convert the SavedModel to TensorFlow.js format using the command line\n",
        "# !tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model ./saved_model ./tfjs_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeLcH84ysrNd",
        "outputId": "7ac040cd-4ccc-4a20-83f4-8ecd59daf2ec"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe kernel failed to start as the Python Environment 'ipynb (Python 3.8.15)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
          ]
        }
      ],
      "source": [
        "# Convert the SavedModel to TensorFlow.js format using the command line\n",
        "!tensorflowjs_converter --input_format=tf_saved_model --output_format=tfjs_graph_model ./saved_model ./tfjs_model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
